{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型中的分词方法\n",
    "NLP任务与一般的机器学习任务有所不同，需要处理的是文本数据，不可以直接输入进深度学习模型，因此在预训练大模型的步骤中，除了\n",
    "首先收集数据（包括网页数据，代码，论文arxiv，百度百科等）以外，训练一个分词器模型，即如何将我们的文本合理的分词，这样对于输入的每一段文本，我们都可以将其映射到数值空间内（token_id），最后结合ROPE旋转位置编码进行encoding输入给我们的模型，通过transformer架构中的自注意力机制可以有效地处理长文本序列，下面我将参考：[大模型中的分词器tokenizer：BPE、WordPiece、Unigram LM、SentencePiece](https://zhuanlan.zhihu.com/p/620508648)这篇文章进行总结。\n",
    "\n",
    "根据不同的粒度区分，常见的分词方法有：\n",
    "- word base:以词为单位，例如：Today is sunday 按照这种分词方法会被分为：[Today ,is,sunday]\n",
    "- character base:以字符为单位，例如： Today is sunday 按照这种分词方法会被分为：[T,o,d,a,y,i,s,u，n，d，a，y， .]\n",
    "- subword base:按照词的subword进行分词。如英文Today is sunday. 则会分割成[To， day，is , s，un，day， .]\n",
    "\n",
    "自GPT2开始，大模型中的常见分词方式为第三种，即以子词的方式进行分词，这里介绍当前预训练大模型中常见的分词方法：Byte Pair Encoding（BPE）\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE算法原理\n",
    "BPE（Byte Pair Encoding）算法是一种数据压缩算法，但在自然语言处理中，它被广泛用于子词单元（subword units）的生成，特别是在处理大型模型的分词训练时。BPE算法通过将常见的字符或字符序列合并成新的单元，从而生成一个词汇表，这个词汇表可以包含从单个字符到完整单词的各种长度的单元。\n",
    "\n",
    "以下是BPE算法的基本步骤：\n",
    "\n",
    "1. 初始化：\n",
    "将词汇表中的每个字符视为一个单独的单元。\n",
    "对于给定的文本数据，统计每个单元（即字符）的出现频率。\n",
    "2. 统计频率：\n",
    "遍历文本数据，统计所有相邻单元对（例如字符对）的出现次数。\n",
    "3. 合并最频繁的单元对：\n",
    "选择出现次数最多的单元对进行合并，形成一个新的单元。\n",
    "更新词汇表，将新单元加入，并删除原来的两个单元。\n",
    "更新所有包含这两个单元的统计信息，用新单元替换它们。\n",
    "4. 迭代：\n",
    "重复步骤2和3，直到达到预设的词汇表大小或迭代次数。\n",
    "生成词汇表：\n",
    "在完成所有迭代后，得到的词汇表包含了从单个字符到较长子词单元的各种长度的单元。\n",
    "5. 编码：\n",
    "使用生成的词汇表对新的文本数据进行编码。这通常意味着将文本拆分成词汇表中的单元序列。\n",
    "\n",
    "BPE算法的优点在于：\n",
    "\n",
    "它能够处理未知单词（OOV，Out-of-Vocabulary words），因为即使一个完整的单词不在词汇表中，它的子词单元也可能在词汇表中。\n",
    "它生成的词汇表大小可控，可以根据需要进行调整。\n",
    "相对于基于规则的分词方法，BPE更加灵活，能够适应不同语言的特点。\n",
    "\n",
    "然而，BPE算法也有一些局限性：\n",
    "\n",
    "它可能会生成一些在语言学上无意义的子词单元。\n",
    "对于某些语言，可能需要更多的上下文信息来正确地进行分词。\n",
    "BPE算法在诸如BERT、GPT等大型语言模型中得到了广泛应用，特别是在处理大规模文本数据和多语言场景时。这些模型通常使用BPE或类似的算法（如SentencePiece、Unigram Language Model等）来生成子词单元，从而有效地处理文本数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe5\\xa5\\xbd'\n"
     ]
    }
   ],
   "source": [
    "# 假设有一个汉字字符串\n",
    "chinese_text = \"好\"\n",
    "\n",
    "# 将汉字字符串编码为UTF-8字节串\n",
    "byte_representation = chinese_text.encode('utf-8')\n",
    "\n",
    "# 输出字节表示\n",
    "print(byte_representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE算法实现---python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections  # 导入需要的库：re 用于正则表达式操作，collections 用于创建字典\n",
    "\n",
    "def get_vocab(filename):\n",
    "    vocab = collections.defaultdict(int)  # 创建一个默认值为0的字典 vocab，用于存储词汇表\n",
    "    with open(filename, 'r', encoding='utf-8') as fhand:  # 打开指定文件以读取内容\n",
    "        for line in fhand:  # 遍历文件的每一行\n",
    "            words = line.strip().split()  # 去除行首尾空格并按空格分割行中的单词\n",
    "            for word in words:  # 遍历每个单词\n",
    "                vocab[' '.join(list(word)) + ' </w>'] += 1  # 将单词拆分为字符列表，用空格连接字符并添加结束符 '</w>'，更新词频统计\n",
    "    return vocab  # 返回生成的词汇表字典\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)  # 创建一个默认值为0的字典 pairs，用于存储字符对的频率统计\n",
    "    for word, freq in vocab.items():  # 遍历词汇表中的每个单词及其频率\n",
    "        symbols = word.split()  # 将单词拆分为字符列表\n",
    "        for i in range(len(symbols)-1):  # 遍历字符列表中除最后一个字符外的每对相邻字符\n",
    "            pairs[symbols[i], symbols[i+1]] += freq  # 统计相邻字符对的频率\n",
    "    return pairs  # 返回字符对的频率统计字典\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}  # 创建一个空字典，用于存储合并后的词汇表\n",
    "    bigram = re.escape(' '.join(pair))  # 将字符对连接成一个大字符，用于正则表达式匹配\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')  # 编译正则表达式，用于在词汇表中查找字符对\n",
    "    for word in v_in:  # 遍历输入的词汇表\n",
    "        w_out = p.sub(''.join(pair), word)  # 使用字符对替换词汇表中的字符对\n",
    "        v_out[w_out] = v_in[word]  # 将替换后的单词及其频率添加到输出词汇表中\n",
    "    return v_out  # 返回合并后的词汇表\n",
    "\n",
    "def get_tokens(vocab):\n",
    "    tokens = collections.defaultdict(int)  # 创建一个默认值为0的字典 tokens，用于存储单词中的各个 token 的频率\n",
    "    for word, freq in vocab.items():  # 遍历词汇表中的每个单词及其频率\n",
    "        word_tokens = word.split()  # 将单词拆分为 token\n",
    "        for token in word_tokens:  # 遍历单词中的每个 token\n",
    "            tokens[token] += freq  # 统计每个 token 的频率\n",
    "    return tokens  # 返回包含 token 频率的字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 举例-----以便清楚内部实现细节\n",
    "vocab_dict = collections.defaultdict(int)\n",
    "with open('vocab.txt', 'r', encoding='utf-8') as fhand:\n",
    "    for line in fhand:\n",
    "        words = line.strip().split()\n",
    "        for word in words:\n",
    "            vocab_dict[' '.join(list(word)) + ' </w>'] +=1\n",
    "pairs = collections.defaultdict(int)  # 创建一个默认值为0的字典 pairs，用于存储字符对的频率统计\n",
    "for word, freq in vocab_dict.items():  # 遍历词汇表中的每个单词及其频率\n",
    "    symbols = word.split()  # 将单词拆分为字符列表\n",
    "    for i in range(len(symbols)-1):  # 遍历字符列表中除最后一个字符外的每对相邻字符\n",
    "        pairs[symbols[i], symbols[i+1]] += freq  # 统计相邻字符对的频率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('\\ufeff', 'T'): 1,\n",
       "             ('T', 'h'): 2,\n",
       "             ('h', 'e'): 17,\n",
       "             ('e', '</w>'): 29,\n",
       "             ('P', 'r'): 6,\n",
       "             ('r', 'o'): 8,\n",
       "             ('o', 'j'): 2,\n",
       "             ('j', 'e'): 2,\n",
       "             ('e', 'c'): 5,\n",
       "             ('c', 't'): 3,\n",
       "             ('t', '</w>'): 16,\n",
       "             ('G', 'u'): 2,\n",
       "             ('u', 't'): 6,\n",
       "             ('t', 'e'): 14,\n",
       "             ('e', 'n'): 5,\n",
       "             ('n', 'b'): 3,\n",
       "             ('b', 'e'): 5,\n",
       "             ('e', 'r'): 11,\n",
       "             ('r', 'g'): 4,\n",
       "             ('g', '</w>'): 5,\n",
       "             ('e', 'B'): 3,\n",
       "             ('B', 'o'): 3,\n",
       "             ('o', 'o'): 9,\n",
       "             ('o', 'k'): 5,\n",
       "             ('k', '</w>'): 5,\n",
       "             ('o', 'f'): 7,\n",
       "             ('f', '</w>'): 6,\n",
       "             ('A', 'l'): 2,\n",
       "             ('l', 'l'): 5,\n",
       "             ('l', '</w>'): 3,\n",
       "             ('A', 'r'): 2,\n",
       "             ('o', 'u'): 7,\n",
       "             ('u', 'n'): 4,\n",
       "             ('n', 'd'): 7,\n",
       "             ('d', '</w>'): 17,\n",
       "             ('t', 'h'): 19,\n",
       "             ('M', 'o'): 3,\n",
       "             ('o', 'n'): 5,\n",
       "             ('n', '</w>'): 4,\n",
       "             ('h', 'i'): 3,\n",
       "             ('i', 's'): 7,\n",
       "             ('s', '</w>'): 10,\n",
       "             ('e', 'b'): 2,\n",
       "             ('b', 'o'): 2,\n",
       "             ('f', 'o'): 2,\n",
       "             ('o', 'r'): 8,\n",
       "             ('r', '</w>'): 6,\n",
       "             ('u', 's'): 4,\n",
       "             ('s', 'e'): 4,\n",
       "             ('a', 'n'): 8,\n",
       "             ('n', 'y'): 2,\n",
       "             ('y', 'o'): 4,\n",
       "             ('n', 'e'): 7,\n",
       "             ('y', 'w'): 1,\n",
       "             ('w', 'h'): 3,\n",
       "             ('r', 'e'): 11,\n",
       "             ('i', 'n'): 9,\n",
       "             ('U', 'n'): 2,\n",
       "             ('n', 'i'): 2,\n",
       "             ('i', 't'): 9,\n",
       "             ('e', 'd'): 11,\n",
       "             ('S', 't'): 2,\n",
       "             ('t', 'a'): 2,\n",
       "             ('a', 't'): 12,\n",
       "             ('e', 's'): 4,\n",
       "             ('m', 'o'): 2,\n",
       "             ('o', 's'): 4,\n",
       "             ('s', 't'): 8,\n",
       "             ('o', 't'): 3,\n",
       "             ('p', 'a'): 1,\n",
       "             ('a', 'r'): 4,\n",
       "             ('r', 't'): 1,\n",
       "             ('t', 's'): 3,\n",
       "             ('w', 'o'): 1,\n",
       "             ('r', 'l'): 1,\n",
       "             ('l', 'd'): 1,\n",
       "             ('n', 'o'): 3,\n",
       "             ('o', '</w>'): 3,\n",
       "             ('c', 'o'): 3,\n",
       "             ('w', 'i'): 3,\n",
       "             ('h', '</w>'): 4,\n",
       "             ('a', 'l'): 3,\n",
       "             ('l', 'm'): 1,\n",
       "             ('t', 'r'): 4,\n",
       "             ('r', 'i'): 3,\n",
       "             ('i', 'c'): 2,\n",
       "             ('t', 'i'): 1,\n",
       "             ('i', 'o'): 1,\n",
       "             ('n', 's'): 3,\n",
       "             ('h', 'a'): 2,\n",
       "             ('s', 'o'): 1,\n",
       "             ('o', 'e'): 1,\n",
       "             ('e', 'v'): 1,\n",
       "             ('v', 'e'): 3,\n",
       "             ('r', '.'): 1,\n",
       "             ('.', '</w>'): 3,\n",
       "             ('Y', 'o'): 1,\n",
       "             ('u', '</w>'): 6,\n",
       "             ('m', 'a'): 1,\n",
       "             ('a', 'y'): 2,\n",
       "             ('y', '</w>'): 7,\n",
       "             ('o', 'p'): 1,\n",
       "             ('p', 'y'): 1,\n",
       "             ('t', ','): 1,\n",
       "             (',', '</w>'): 6,\n",
       "             ('g', 'i'): 1,\n",
       "             ('i', 'v'): 1,\n",
       "             ('a', 'w'): 2,\n",
       "             ('w', 'a'): 2,\n",
       "             ('e', '-'): 1,\n",
       "             ('-', 'u'): 1,\n",
       "             ('d', 'e'): 2,\n",
       "             ('r', 'm'): 1,\n",
       "             ('m', 's'): 1,\n",
       "             ('L', 'i'): 1,\n",
       "             ('c', 'e'): 5,\n",
       "             ('n', 'c'): 1,\n",
       "             ('c', 'l'): 1,\n",
       "             ('l', 'u'): 1,\n",
       "             ('u', 'd'): 1,\n",
       "             ('n', 'l'): 3,\n",
       "             ('l', 'i'): 4,\n",
       "             ('w', 'w'): 6,\n",
       "             ('w', '.'): 3,\n",
       "             ('.', 'g'): 1,\n",
       "             ('g', 'u'): 3,\n",
       "             ('g', '.'): 2,\n",
       "             ('.', 'o'): 1,\n",
       "             ('I', 'f'): 1,\n",
       "             ('l', 'o'): 2,\n",
       "             ('o', 'c'): 2,\n",
       "             ('c', 'a'): 2,\n",
       "             ('s', ','): 1,\n",
       "             ('i', 'l'): 1,\n",
       "             ('a', 'v'): 3,\n",
       "             ('t', 'o'): 2,\n",
       "             ('c', 'h'): 1,\n",
       "             ('c', 'k'): 1,\n",
       "             ('l', 'a'): 4,\n",
       "             ('w', 's'): 1,\n",
       "             ('n', 't'): 2,\n",
       "             ('r', 'y'): 1,\n",
       "             ('e', 'f'): 1,\n",
       "             ('s', 'i'): 1,\n",
       "             ('n', 'g'): 5,\n",
       "             ('k', '.'): 1,\n",
       "             ('T', 'i'): 1,\n",
       "             ('t', 'l'): 2,\n",
       "             ('l', 'e'): 3,\n",
       "             ('e', ':'): 3,\n",
       "             (':', '</w>'): 7,\n",
       "             ('A', 'u'): 2,\n",
       "             ('h', 'o'): 1,\n",
       "             ('r', ':'): 2,\n",
       "             ('J', 'u'): 1,\n",
       "             ('u', 'l'): 1,\n",
       "             ('V', 'e'): 1,\n",
       "             ('r', 'n'): 1,\n",
       "             ('T', 'r'): 1,\n",
       "             ('r', 'a'): 3,\n",
       "             ('s', 'l'): 1,\n",
       "             ('E', 'd'): 1,\n",
       "             ('d', 'w'): 1,\n",
       "             ('r', 'd'): 1,\n",
       "             ('R', 'o'): 1,\n",
       "             ('R', 'e'): 1,\n",
       "             ('e', 'l'): 1,\n",
       "             ('e', 'a'): 5,\n",
       "             ('a', 's'): 1,\n",
       "             ('d', 'a'): 2,\n",
       "             ('u', 'g'): 1,\n",
       "             ('6', ','): 1,\n",
       "             ('2', '0'): 3,\n",
       "             ('0', '0'): 1,\n",
       "             ('0', '5'): 1,\n",
       "             ('5', '</w>'): 1,\n",
       "             ('[', 'e'): 1,\n",
       "             ('#', '1'): 1,\n",
       "             ('1', '6'): 1,\n",
       "             ('6', '4'): 1,\n",
       "             ('4', '5'): 1,\n",
       "             ('5', '7'): 1,\n",
       "             ('7', ']'): 1,\n",
       "             (']', '</w>'): 1,\n",
       "             ('l', 'y'): 1,\n",
       "             ('u', 'p'): 1,\n",
       "             ('p', 'd'): 1,\n",
       "             ('d', ':'): 1,\n",
       "             ('D', 'e'): 1,\n",
       "             ('e', 'm'): 1,\n",
       "             ('m', 'b'): 1,\n",
       "             ('1', '2'): 1,\n",
       "             ('2', ','): 1,\n",
       "             ('0', '2'): 1,\n",
       "             ('0', '</w>'): 1,\n",
       "             ('L', 'a'): 1,\n",
       "             ('u', 'a'): 1,\n",
       "             ('a', 'g'): 1,\n",
       "             ('g', 'e'): 1,\n",
       "             ('E', 'n'): 1,\n",
       "             ('g', 'l'): 1,\n",
       "             ('s', 'h'): 1,\n",
       "             ('C', 'r'): 1,\n",
       "             ('d', 'i'): 3,\n",
       "             ('s', ':'): 3,\n",
       "             ('o', 'd'): 2,\n",
       "             ('d', 'u'): 2,\n",
       "             ('u', 'c'): 2,\n",
       "             ('b', 'y'): 2,\n",
       "             ('A', 'f'): 2,\n",
       "             ('f', 'r'): 4,\n",
       "             ('a', '</w>'): 2,\n",
       "             ('U', 'l'): 2,\n",
       "             ('a', 'h'): 2,\n",
       "             ('h', ','): 2,\n",
       "             ('T', 'a'): 2,\n",
       "             ('a', 'a'): 2,\n",
       "             ('v', 'i'): 2,\n",
       "             ('i', '</w>'): 2,\n",
       "             ('K', 'a'): 2,\n",
       "             ('l', 'j'): 2,\n",
       "             ('j', 'u'): 2,\n",
       "             ('O', 'n'): 2,\n",
       "             ('D', 'i'): 2,\n",
       "             ('i', 'b'): 2,\n",
       "             ('b', 'u'): 2,\n",
       "             ('a', 'd'): 2,\n",
       "             ('T', 'e'): 2,\n",
       "             ('a', 'm'): 2,\n",
       "             ('m', '</w>'): 2,\n",
       "             ('h', 't'): 2,\n",
       "             ('t', 't'): 2,\n",
       "             ('t', 'p'): 2,\n",
       "             ('p', 's'): 2,\n",
       "             (':', '/'): 2,\n",
       "             ('/', '/'): 2,\n",
       "             ('/', 'w'): 2,\n",
       "             ('.', 'p'): 2,\n",
       "             ('p', 'g'): 2,\n",
       "             ('g', 'd'): 2,\n",
       "             ('d', 'p'): 2,\n",
       "             ('p', '.'): 2,\n",
       "             ('.', 'n'): 2,\n",
       "             ('e', 't'): 2,\n",
       "             ('*', '*'): 4,\n",
       "             ('*', '</w>'): 2,\n",
       "             ('S', 'T'): 1,\n",
       "             ('T', 'A'): 1,\n",
       "             ('A', 'R'): 2,\n",
       "             ('R', 'T'): 1,\n",
       "             ('T', '</w>'): 2,\n",
       "             ('O', 'F'): 1,\n",
       "             ('F', '</w>'): 1,\n",
       "             ('T', 'H'): 2,\n",
       "             ('H', 'E'): 2,\n",
       "             ('E', '</w>'): 2,\n",
       "             ('P', 'R'): 1,\n",
       "             ('R', 'O'): 2,\n",
       "             ('O', 'J'): 1,\n",
       "             ('J', 'E'): 1,\n",
       "             ('E', 'C'): 1,\n",
       "             ('C', 'T'): 1,\n",
       "             ('G', 'U'): 1,\n",
       "             ('U', 'T'): 1,\n",
       "             ('T', 'E'): 1,\n",
       "             ('E', 'N'): 1,\n",
       "             ('N', 'B'): 1,\n",
       "             ('B', 'E'): 1,\n",
       "             ('E', 'R'): 1,\n",
       "             ('R', 'G'): 1,\n",
       "             ('G', '</w>'): 1,\n",
       "             ('E', 'B'): 1,\n",
       "             ('B', 'O'): 1,\n",
       "             ('O', 'O'): 2,\n",
       "             ('O', 'K'): 1,\n",
       "             ('K', '</w>'): 1,\n",
       "             ('A', 'L'): 1,\n",
       "             ('L', 'L'): 1,\n",
       "             ('L', '</w>'): 1,\n",
       "             ('O', 'U'): 1,\n",
       "             ('U', 'N'): 1,\n",
       "             ('N', 'D'): 1,\n",
       "             ('D', '</w>'): 1,\n",
       "             ('M', 'O'): 1,\n",
       "             ('O', 'N'): 1,\n",
       "             ('N', '</w>'): 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', '</w>')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到当前相邻字符对出现次数最多的\n",
    "max_pairs = max(pairs,key=pairs.get)\n",
    "max_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " T h e</w>\n",
      "P r o j e c t </w>\n",
      "G u t e n b e r g </w>\n",
      "e B o o k </w>\n",
      "o f </w>\n",
      "A l l </w>\n",
      "A r o u n d </w>\n",
      "t h e</w>\n",
      "M o o n </w>\n",
      "T h i s </w>\n",
      "e b o o k </w>\n",
      "i s </w>\n",
      "f o r </w>\n",
      "u s e</w>\n",
      "a n y o n e</w>\n",
      "a n y w h e r e</w>\n",
      "i n </w>\n",
      "U n i t e d </w>\n",
      "S t a t e s </w>\n",
      "a n d </w>\n",
      "m o s t </w>\n",
      "o t h e r </w>\n",
      "p a r t s </w>\n",
      "w o r l d </w>\n",
      "a t </w>\n",
      "n o </w>\n",
      "c o s t </w>\n",
      "w i t h </w>\n",
      "a l m o s t </w>\n",
      "r e s t r i c t i o n s </w>\n",
      "w h a t s o e v e r . </w>\n",
      "Y o u </w>\n",
      "m a y </w>\n",
      "c o p y </w>\n",
      "i t , </w>\n",
      "g i v e</w>\n",
      "i t </w>\n",
      "a w a y </w>\n",
      "o r </w>\n",
      "r e - u s e</w>\n",
      "u n d e r </w>\n",
      "t e r m s </w>\n",
      "L i c e n s e</w>\n",
      "i n c l u d e d </w>\n",
      "t h i s </w>\n",
      "o n l i n e</w>\n",
      "w w w . g u t e n b e r g . o r g . </w>\n",
      "I f </w>\n",
      "y o u </w>\n",
      "a r e</w>\n",
      "n o t </w>\n",
      "l o c a t e d </w>\n",
      "S t a t e s , </w>\n",
      "w i l l </w>\n",
      "h a v e</w>\n",
      "t o </w>\n",
      "c h e c k </w>\n",
      "l a w s </w>\n",
      "c o u n t r y </w>\n",
      "w h e r e</w>\n",
      "b e f o r e</w>\n",
      "u s i n g </w>\n",
      "e B o o k . </w>\n",
      "T i t l e : </w>\n",
      "A u t h o r : </w>\n",
      "J u l e s </w>\n",
      "V e r n e</w>\n",
      "T r a n s l a t o r : </w>\n",
      "E d w a r d </w>\n",
      "R o t h </w>\n",
      "R e l e a s e</w>\n",
      "d a t e : </w>\n",
      "A u g u s t </w>\n",
      "6 , </w>\n",
      "2 0 0 5 </w>\n",
      "[ e B o o k </w>\n",
      "# 1 6 4 5 7 ] </w>\n",
      "M o s t </w>\n",
      "r e c e n t l y </w>\n",
      "u p d a t e d : </w>\n",
      "D e c e m b e r </w>\n",
      "1 2 , </w>\n",
      "2 0 2 0 </w>\n",
      "L a n g u a g e : </w>\n",
      "E n g l i s h </w>\n",
      "C r e d i t s : </w>\n",
      "P r o d u c e d </w>\n",
      "b y </w>\n",
      "A f r a </w>\n",
      "U l l a h , </w>\n",
      "T a a v i </w>\n",
      "K a l j u </w>\n",
      "O n l i n e</w>\n",
      "D i s t r i b u t e d </w>\n",
      "P r o o f r e a d i n g </w>\n",
      "T e a m </w>\n",
      "h t t p s : / / w w w . p g d p . n e t </w>\n",
      "* * * </w>\n",
      "S T A R T </w>\n",
      "O F </w>\n",
      "T H E </w>\n",
      "P R O J E C T </w>\n",
      "G U T E N B E R G </w>\n",
      "E B O O K </w>\n",
      "A L L </w>\n",
      "A R O U N D </w>\n",
      "M O O N </w>\n"
     ]
    }
   ],
   "source": [
    "v_out = {}  # 创建一个空字典，用于存储合并后的词汇表\n",
    "bigram = re.escape(' '.join(max_pairs))  # 将字符对连接成一个大字符，用于正则表达式匹配\n",
    "p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')  # 编译正则表达式，用于在词汇表中查找字符对\n",
    "for word in vocab_dict:  # 遍历输入的词汇表\n",
    "    w_out = p.sub(''.join(max_pairs), word)  # 使用字符对替换词汇表中的字符对\n",
    "    print(w_out)\n",
    "    v_out[w_out] = vocab_dict[word]  # 将替换后的单词及其频率添加到输出词汇表中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'\\ufeff T h e </w>': 1,\n",
       "             'P r o j e c t </w>': 2,\n",
       "             'G u t e n b e r g </w>': 2,\n",
       "             'e B o o k </w>': 1,\n",
       "             'o f </w>': 5,\n",
       "             'A l l </w>': 2,\n",
       "             'A r o u n d </w>': 2,\n",
       "             't h e </w>': 12,\n",
       "             'M o o n </w>': 2,\n",
       "             'T h i s </w>': 1,\n",
       "             'e b o o k </w>': 2,\n",
       "             'i s </w>': 1,\n",
       "             'f o r </w>': 1,\n",
       "             'u s e </w>': 1,\n",
       "             'a n y o n e </w>': 1,\n",
       "             'a n y w h e r e </w>': 1,\n",
       "             'i n </w>': 2,\n",
       "             'U n i t e d </w>': 2,\n",
       "             'S t a t e s </w>': 1,\n",
       "             'a n d </w>': 4,\n",
       "             'm o s t </w>': 1,\n",
       "             'o t h e r </w>': 1,\n",
       "             'p a r t s </w>': 1,\n",
       "             'w o r l d </w>': 1,\n",
       "             'a t </w>': 4,\n",
       "             'n o </w>': 2,\n",
       "             'c o s t </w>': 1,\n",
       "             'w i t h </w>': 2,\n",
       "             'a l m o s t </w>': 1,\n",
       "             'r e s t r i c t i o n s </w>': 1,\n",
       "             'w h a t s o e v e r . </w>': 1,\n",
       "             'Y o u </w>': 1,\n",
       "             'm a y </w>': 1,\n",
       "             'c o p y </w>': 1,\n",
       "             'i t , </w>': 1,\n",
       "             'g i v e </w>': 1,\n",
       "             'i t </w>': 2,\n",
       "             'a w a y </w>': 1,\n",
       "             'o r </w>': 2,\n",
       "             'r e - u s e </w>': 1,\n",
       "             'u n d e r </w>': 1,\n",
       "             't e r m s </w>': 1,\n",
       "             'L i c e n s e </w>': 1,\n",
       "             'i n c l u d e d </w>': 1,\n",
       "             't h i s </w>': 2,\n",
       "             'o n l i n e </w>': 1,\n",
       "             'w w w . g u t e n b e r g . o r g . </w>': 1,\n",
       "             'I f </w>': 1,\n",
       "             'y o u </w>': 3,\n",
       "             'a r e </w>': 2,\n",
       "             'n o t </w>': 1,\n",
       "             'l o c a t e d </w>': 2,\n",
       "             'S t a t e s , </w>': 1,\n",
       "             'w i l l </w>': 1,\n",
       "             'h a v e </w>': 1,\n",
       "             't o </w>': 1,\n",
       "             'c h e c k </w>': 1,\n",
       "             'l a w s </w>': 1,\n",
       "             'c o u n t r y </w>': 1,\n",
       "             'w h e r e </w>': 1,\n",
       "             'b e f o r e </w>': 1,\n",
       "             'u s i n g </w>': 1,\n",
       "             'e B o o k . </w>': 1,\n",
       "             'T i t l e : </w>': 1,\n",
       "             'A u t h o r : </w>': 1,\n",
       "             'J u l e s </w>': 1,\n",
       "             'V e r n e </w>': 1,\n",
       "             'T r a n s l a t o r : </w>': 1,\n",
       "             'E d w a r d </w>': 1,\n",
       "             'R o t h </w>': 1,\n",
       "             'R e l e a s e </w>': 1,\n",
       "             'd a t e : </w>': 1,\n",
       "             'A u g u s t </w>': 1,\n",
       "             '6 , </w>': 1,\n",
       "             '2 0 0 5 </w>': 1,\n",
       "             '[ e B o o k </w>': 1,\n",
       "             '# 1 6 4 5 7 ] </w>': 1,\n",
       "             'M o s t </w>': 1,\n",
       "             'r e c e n t l y </w>': 1,\n",
       "             'u p d a t e d : </w>': 1,\n",
       "             'D e c e m b e r </w>': 1,\n",
       "             '1 2 , </w>': 1,\n",
       "             '2 0 2 0 </w>': 1,\n",
       "             'L a n g u a g e : </w>': 1,\n",
       "             'E n g l i s h </w>': 1,\n",
       "             'C r e d i t s : </w>': 1,\n",
       "             'P r o d u c e d </w>': 2,\n",
       "             'b y </w>': 2,\n",
       "             'A f r a </w>': 2,\n",
       "             'U l l a h , </w>': 2,\n",
       "             'T a a v i </w>': 2,\n",
       "             'K a l j u </w>': 2,\n",
       "             'O n l i n e </w>': 2,\n",
       "             'D i s t r i b u t e d </w>': 2,\n",
       "             'P r o o f r e a d i n g </w>': 2,\n",
       "             'T e a m </w>': 2,\n",
       "             'h t t p s : / / w w w . p g d p . n e t </w>': 2,\n",
       "             '* * * </w>': 2,\n",
       "             'S T A R T </w>': 1,\n",
       "             'O F </w>': 1,\n",
       "             'T H E </w>': 2,\n",
       "             'P R O J E C T </w>': 1,\n",
       "             'G U T E N B E R G </w>': 1,\n",
       "             'E B O O K </w>': 1,\n",
       "             'A L L </w>': 1,\n",
       "             'A R O U N D </w>': 1,\n",
       "             'M O O N </w>': 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\ufeff T h e</w>': 1,\n",
       " 'P r o j e c t </w>': 2,\n",
       " 'G u t e n b e r g </w>': 2,\n",
       " 'e B o o k </w>': 1,\n",
       " 'o f </w>': 5,\n",
       " 'A l l </w>': 2,\n",
       " 'A r o u n d </w>': 2,\n",
       " 't h e</w>': 12,\n",
       " 'M o o n </w>': 2,\n",
       " 'T h i s </w>': 1,\n",
       " 'e b o o k </w>': 2,\n",
       " 'i s </w>': 1,\n",
       " 'f o r </w>': 1,\n",
       " 'u s e</w>': 1,\n",
       " 'a n y o n e</w>': 1,\n",
       " 'a n y w h e r e</w>': 1,\n",
       " 'i n </w>': 2,\n",
       " 'U n i t e d </w>': 2,\n",
       " 'S t a t e s </w>': 1,\n",
       " 'a n d </w>': 4,\n",
       " 'm o s t </w>': 1,\n",
       " 'o t h e r </w>': 1,\n",
       " 'p a r t s </w>': 1,\n",
       " 'w o r l d </w>': 1,\n",
       " 'a t </w>': 4,\n",
       " 'n o </w>': 2,\n",
       " 'c o s t </w>': 1,\n",
       " 'w i t h </w>': 2,\n",
       " 'a l m o s t </w>': 1,\n",
       " 'r e s t r i c t i o n s </w>': 1,\n",
       " 'w h a t s o e v e r . </w>': 1,\n",
       " 'Y o u </w>': 1,\n",
       " 'm a y </w>': 1,\n",
       " 'c o p y </w>': 1,\n",
       " 'i t , </w>': 1,\n",
       " 'g i v e</w>': 1,\n",
       " 'i t </w>': 2,\n",
       " 'a w a y </w>': 1,\n",
       " 'o r </w>': 2,\n",
       " 'r e - u s e</w>': 1,\n",
       " 'u n d e r </w>': 1,\n",
       " 't e r m s </w>': 1,\n",
       " 'L i c e n s e</w>': 1,\n",
       " 'i n c l u d e d </w>': 1,\n",
       " 't h i s </w>': 2,\n",
       " 'o n l i n e</w>': 1,\n",
       " 'w w w . g u t e n b e r g . o r g . </w>': 1,\n",
       " 'I f </w>': 1,\n",
       " 'y o u </w>': 3,\n",
       " 'a r e</w>': 2,\n",
       " 'n o t </w>': 1,\n",
       " 'l o c a t e d </w>': 2,\n",
       " 'S t a t e s , </w>': 1,\n",
       " 'w i l l </w>': 1,\n",
       " 'h a v e</w>': 1,\n",
       " 't o </w>': 1,\n",
       " 'c h e c k </w>': 1,\n",
       " 'l a w s </w>': 1,\n",
       " 'c o u n t r y </w>': 1,\n",
       " 'w h e r e</w>': 1,\n",
       " 'b e f o r e</w>': 1,\n",
       " 'u s i n g </w>': 1,\n",
       " 'e B o o k . </w>': 1,\n",
       " 'T i t l e : </w>': 1,\n",
       " 'A u t h o r : </w>': 1,\n",
       " 'J u l e s </w>': 1,\n",
       " 'V e r n e</w>': 1,\n",
       " 'T r a n s l a t o r : </w>': 1,\n",
       " 'E d w a r d </w>': 1,\n",
       " 'R o t h </w>': 1,\n",
       " 'R e l e a s e</w>': 1,\n",
       " 'd a t e : </w>': 1,\n",
       " 'A u g u s t </w>': 1,\n",
       " '6 , </w>': 1,\n",
       " '2 0 0 5 </w>': 1,\n",
       " '[ e B o o k </w>': 1,\n",
       " '# 1 6 4 5 7 ] </w>': 1,\n",
       " 'M o s t </w>': 1,\n",
       " 'r e c e n t l y </w>': 1,\n",
       " 'u p d a t e d : </w>': 1,\n",
       " 'D e c e m b e r </w>': 1,\n",
       " '1 2 , </w>': 1,\n",
       " '2 0 2 0 </w>': 1,\n",
       " 'L a n g u a g e : </w>': 1,\n",
       " 'E n g l i s h </w>': 1,\n",
       " 'C r e d i t s : </w>': 1,\n",
       " 'P r o d u c e d </w>': 2,\n",
       " 'b y </w>': 2,\n",
       " 'A f r a </w>': 2,\n",
       " 'U l l a h , </w>': 2,\n",
       " 'T a a v i </w>': 2,\n",
       " 'K a l j u </w>': 2,\n",
       " 'O n l i n e</w>': 2,\n",
       " 'D i s t r i b u t e d </w>': 2,\n",
       " 'P r o o f r e a d i n g </w>': 2,\n",
       " 'T e a m </w>': 2,\n",
       " 'h t t p s : / / w w w . p g d p . n e t </w>': 2,\n",
       " '* * * </w>': 2,\n",
       " 'S T A R T </w>': 1,\n",
       " 'O F </w>': 1,\n",
       " 'T H E </w>': 2,\n",
       " 'P R O J E C T </w>': 1,\n",
       " 'G U T E N B E R G </w>': 1,\n",
       " 'E B O O K </w>': 1,\n",
       " 'A L L </w>': 1,\n",
       " 'A R O U N D </w>': 1,\n",
       " 'M O O N </w>': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs1 = get_stats(v_out)\n",
    "pairs1_ = max(pairs1,key=pairs1.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'h')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Tokens Before BPE\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 31, 'e': 85, '</w>': 158, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'c': 16, 't': 68, 'G': 4, 'u': 27, 'n': 42, 'b': 11, 'g': 15, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd': 30, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 63\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 以pg16457.txt为例\n",
    "vocab = get_vocab('vocab.txt')\n",
    "\n",
    "print('=========='*5)\n",
    "print('Tokens Before BPE')\n",
    "tokens = get_tokens(vocab)\n",
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))\n",
    "print('=========='*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Best pair: ('e', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 31, 'e</w>': 29, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 56, 'c': 16, 't': 68, '</w>': 129, 'G': 4, 'u': 27, 'n': 42, 'b': 11, 'g': 15, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd': 30, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 64\n",
      "==========\n",
      "Iter: 1\n",
      "Best pair: ('t', 'h')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 29, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 56, 'c': 16, 't': 49, '</w>': 129, 'G': 4, 'u': 27, 'n': 42, 'b': 11, 'g': 15, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd': 30, 'th': 19, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 65\n",
      "==========\n",
      "Iter: 2\n",
      "Best pair: ('d', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 29, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 56, 'c': 16, 't': 49, '</w>': 112, 'G': 4, 'u': 27, 'n': 42, 'b': 11, 'g': 15, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'th': 19, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 66\n",
      "==========\n",
      "Iter: 3\n",
      "Best pair: ('t', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 29, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 56, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 't': 33, 'n': 42, 'b': 11, 'g': 15, '</w>': 96, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'th': 19, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 67\n",
      "==========\n",
      "Iter: 4\n",
      "Best pair: ('t', 'e')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 29, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 42, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 42, 'b': 11, 'g': 15, '</w>': 96, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'th': 19, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 68\n",
      "==========\n",
      "Iter: 5\n",
      "Best pair: ('th', 'e</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 17, 'P': 7, 'r': 44, 'o': 59, 'j': 4, 'e': 42, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 42, 'b': 11, 'g': 15, '</w>': 96, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'the</w>': 12, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'th': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 69\n",
      "==========\n",
      "Iter: 6\n",
      "Best pair: ('e', 'r')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 17, 'P': 7, 'r': 34, 'o': 59, 'j': 4, 'e': 32, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 42, 'b': 11, 'er': 10, 'g': 15, '</w>': 96, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'the</w>': 12, 'M': 4, 'i': 34, 's': 30, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'th': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 70\n",
      "==========\n",
      "Iter: 7\n",
      "Best pair: ('s', '</w>')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 17, 'P': 7, 'r': 34, 'o': 59, 'j': 4, 'e': 32, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 42, 'b': 11, 'er': 10, 'g': 15, '</w>': 86, 'B': 5, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'the</w>': 12, 'M': 4, 'i': 34, 's</w>': 10, 's': 20, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'th': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 71\n",
      "==========\n",
      "Iter: 8\n",
      "Best pair: ('o', 'o')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 17, 'P': 7, 'r': 34, 'o': 41, 'j': 4, 'e': 32, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 42, 'b': 11, 'er': 10, 'g': 15, '</w>': 86, 'B': 5, 'oo': 9, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'the</w>': 12, 'M': 4, 'i': 34, 's</w>': 10, 's': 20, 'a': 46, 'y': 12, 'w': 19, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'th': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 72\n",
      "==========\n",
      "Iter: 9\n",
      "Best pair: ('i', 'n')\n",
      "Tokens: defaultdict(<class 'int'>, {'\\ufeff': 1, 'T': 14, 'h': 12, 'e</w>': 17, 'P': 7, 'r': 34, 'o': 41, 'j': 4, 'e': 32, 'c': 16, 't</w>': 16, 'G': 4, 'u': 27, 'te': 14, 'n': 33, 'b': 11, 'er': 10, 'g': 15, '</w>': 86, 'B': 5, 'oo': 9, 'k': 6, 'f': 12, 'A': 11, 'l': 27, 'd</w>': 17, 'the</w>': 12, 'M': 4, 'i': 25, 's</w>': 10, 's': 20, 'a': 46, 'y': 12, 'w': 19, 'in': 9, 'U': 6, 'S': 3, 't': 19, 'm': 7, 'th': 7, 'p': 9, 'v': 5, '.': 9, 'Y': 1, ',': 6, '-': 1, 'd': 13, 'L': 4, 'I': 1, ':': 9, 'J': 2, 'V': 1, 'E': 8, 'R': 6, '6': 2, '2': 4, '0': 4, '5': 2, '[': 1, '#': 1, '1': 2, '4': 1, '7': 1, ']': 1, 'D': 4, 'C': 2, 'K': 3, 'O': 9, '/': 4, '*': 6, 'F': 1, 'H': 2, 'N': 3})\n",
      "Number of tokens: 73\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# 开始合并\n",
    "num_merges = 10\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print('Iter: {}'.format(i))\n",
    "    print('Best pair: {}'.format(best))\n",
    "    tokens = get_tokens(vocab)\n",
    "    print('Tokens: {}'.format(tokens))\n",
    "    print('Number of tokens: {}'.format(len(tokens)))\n",
    "    print('==========')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
