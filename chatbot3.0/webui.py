
'''
2024-5-23æ›´æ–°ï¼š
æ›´æ–°å†…å®¹ï¼š
1. ä½¿ç”¨langchainæ¡†æ¶å¤„ç†PDF
2. å¢åŠ å…¶ä»–æ ¼å¼çš„æ–‡ä»¶å¤„ç†ï¼Œå¦‚ word,pptx,txt,markdownç­‰

2024-6-10æ›´æ–°ï¼š
1.æ–°å¢ä¸Šä¼ PPTæ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨RapidOCRè¿›è¡Œæ–‡å­—è¯†åˆ«
2.æ–°å¢RAGé‡æ’åŠŸèƒ½ï¼Œåˆæ’ä½¿ç”¨BM25æ£€ç´¢ï¼Œé‡æ’ä½¿ç”¨rerank_modelè¿›è¡Œé‡æ’ï¼Œä»¥æé«˜å‡†ç¡®ç‡
3.æ–°å¢æœ¬äººè®­ç»ƒç¨ å¯†æ¨¡å‹NDLSLM-0.8B-Chatä¸MOEæ¨¡å‹NDLMoe-1.3B-Chatçš„æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œå¹¶ä½¿ç”¨å¤šè½®å¯¹è¯è¿›è¡Œé—®ç­”
4.æ–°å¢æ·»åŠ å·¥å…·åŠŸèƒ½ï¼ŒLLMå¯æ ¹æ®æä¾›çš„å·¥å…·è‡ªè¡Œè¿›è¡Œæ„å›¾è¯†åˆ«å›ç­”ç›¸åº”å†…å®¹ï¼Œå¦‚ï¼š1.è¯¢é—®å¤©æ°”ï¼ˆè”ç½‘åŠŸèƒ½ï¼‰2.é—®ç­”ï¼ˆæœ¬åœ°çŸ¥è¯†åº“é—®ç­”ï¼‰3.æ€»ç»“ç½‘é¡µé“¾æ¥å†…å®¹
'''
import gradio as gr
from file_preprocess import process_pdf, process_txt, process_word, process_md,process_pptx,process_url
import json
import torch
import requests
from requests.adapters import HTTPAdapter
from doc_retrieve import doc_retrive
import hashlib
from http import HTTPStatus
import dashscope
from dashscope import Generation
from PIL import Image
from langchain.prompts import ChatPromptTemplate
import os
import random
from dashscope import ImageSynthesis
############################################################
your_api_key = '' #è¿™é‡Œè¦å¡«å†™ä½ è‡ªå·±çš„apiï¼ˆapiå¼€é€šç½‘å€ï¼šhttps://help.aliyun.com/zh/dashscope/developer-reference/activate-dashscope-and-create-an-api-key?spm=a2c4g.11186623.0.0.6c2774fahtfXdnï¼‰
dashscope.api_key= your_api_key
weather_key = '' #è·å–keyåœ°å€ï¼šhttps://www.seniverse.com/dashboard
# ç½‘é¡µè§£æç¤ºä¾‹ï¼šhttps://answer.baidu.com/answer/land?params=lgABMtSy4ujOLvFFM2sGFVCExgpuadEDBMkyOgrYum117hshYtLo7FSn8a97f0w%2FFYCbR%2BFXMoekSa64GxqSfa103cZJe7IdVMHDAtZeKqZ7wdr8hrO9ff6JvQAZZIr7JNQ1CKmA9Hnd3GG6Fdfom4Llv9xZfgRDTEdr00V%2BdkVHrIY559uKblL%2FamqRk41amfl0T9sri3VOktewKS9rsA%3D%3D&from=dqa&lid=b1e08f6f000d26f3&word=%E5%A6%82%E4%BD%95%E7%A7%8D%E6%A4%8D%E5%A4%9A%E8%82%89%E6%A4%8D%E7%89%A9
############################################################

def classify_task(prompt,url = 'qwen-turbo'):
    messages = [
        {'role': 'user', 'content': prompt}]
    responses = Generation.call(url,
                                messages=messages,
                                result_format='message',  # è®¾ç½®è¾“å‡ºä¸º'message'æ ¼å¼
                                stream=True, # è®¾ç½®è¾“å‡ºæ–¹å¼ä¸ºæµå¼è¾“å‡º
                                incremental_output=True  # å¢é‡å¼æµå¼è¾“å‡º
                                )
    res = ''
    for response in responses:
        if response.status_code == HTTPStatus.OK:
            res+=response.output.choices[0]['message']['content']
        else:
            res = 'é‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–è€…apiä½™é¢'
    
    return res
def call_city_weather(city):
    params = {
        "key": weather_key,
        "location": city,
        "language": "zh-Hans",
        "unit": "c",
    }
    url = "https://api.seniverse.com/v3/weather/now.json"
    r = requests.get(url, params=params)
    data = r.json()["results"]
    address = data[0]["location"]['path']
    temperature = data[0]['now']["temperature"]
    text = data[0]['now']["text"]
    return address+"å½“å‰å¤©æ°”ï¼š"+text+"ï¼Œæ¸©åº¦ï¼š"+temperature+ "â„ƒ"
def call_image_generation(prompt):
    rsp = ImageSynthesis.call(model=ImageSynthesis.Models.wanx_v1,
                              prompt=prompt,
                              n=1, #é»˜è®¤ç”Ÿæˆä¸€å¼ å›¾ç‰‡
                              size='720*1280')
    if rsp.status_code == HTTPStatus.OK:
        image_url = rsp.output['results'][0]['url']
    else:
        image_url =  'error'
    return image_url
input_messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]
def call_with_stream(prompt,url):
    global input_messages
    print('å½“å‰ç”¨æˆ·é—®é¢˜ï¼š',prompt)
    input_messages.append({'role': 'user', 'content': prompt})
    responses = Generation.call(url,
                                messages=input_messages,
                                result_format='message',  # è®¾ç½®è¾“å‡ºä¸º'message'æ ¼å¼
                                stream=True, # è®¾ç½®è¾“å‡ºæ–¹å¼ä¸ºæµå¼è¾“å‡º
                                incremental_output=True  # å¢é‡å¼æµå¼è¾“å‡º
                                )
    cur_sys = ''
    cur_res = ''
    for response in responses:
        if response.status_code == HTTPStatus.OK:
            cur_sys =response.output.choices[0]['message']['role']
            cur_res+=response.output.choices[0]['message']['content']
            yield response.output.choices[0]['message']['content']
        else:
            yield 'å½“å‰å¯¹è¯å‡ºé”™ï¼Œè¯·åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æ£€æŸ¥æ‚¨çš„ç½‘ç»œä»¥åŠAPIä½™é¢'
            # å¦‚æœå“åº”å¤±è´¥ï¼Œå°†æœ€åä¸€æ¡user messageä»messagesåˆ—è¡¨é‡Œåˆ é™¤ï¼Œç¡®ä¿user/assistantæ¶ˆæ¯äº¤æ›¿å‡ºç°
            input_messages = input_messages[:-1]
            break
    input_messages.append({'role': cur_sys,
                         'content': cur_res})
    print(input_messages)
def image2text_call(image_name,prompt):
    # å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼šå›¾ç‰‡ç”Ÿæˆæ–‡æœ¬
    image_path_input = 'file://./user_files/image/'+image_name
    # 'file://./files/dog_and_girl.jpeg'
    messages = [
        {
            "role": "user",
            "content": [
                {"image": image_path_input},
                {"text": prompt}
            ]
        }
    ]
    responses = dashscope.MultiModalConversation.call(model='qwen-vl-plus',
                                                     messages=messages,
                                                     stream=True,
                                                     incremental_output=True )
    for response in responses:
        if response.status_code == HTTPStatus.OK and response.output.choices[0]['message']['content']:
            yield response.output.choices[0]['message']['content'][0]['text']
        
# å…¨å±€å˜é‡ç”¨äºç¼“å­˜æ–‡æœ¬æ–‡ä»¶å¤„ç†ç»“æœ
cached_file_content = None
cached_file_hash = None
task_res = None
def calculate_file_hash(file_path):
    hasher = hashlib.md5()
    with open(file_path, 'rb') as afile:
        buf = afile.read()
        hasher.update(buf)
    return hasher.hexdigest()

def call_llm(prompt, url): ####ä½ è‡ªå·±éƒ¨ç½²çš„Qwenæ¨¡å‹APIåœ°å€-----é€‚ç”¨äºQwen1.0
    headers = {"Content-Type": "application/json"}
    data = json.dumps({"prompt": prompt})
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=3))
    try:
        res = s.post(url, data=data, headers=headers, timeout=600)
        if res.status_code == 200:
            return res.json()['response']
        else:
            return None
    except requests.exceptions.RequestException as e:
        print(e)
        return None

def save_text(content,file_name):
    save_dir = "./user_files/text"
    os.makedirs(save_dir, exist_ok=True)
    # è·å–ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
    file_name = os.path.basename(file_name.name)
    file_name = file_name.split('.')[0]+'.txt'
    # å®šä¹‰ä¿å­˜è·¯å¾„
    save_path = os.path.join(save_dir, file_name)
    # æ‰“å¼€æ–‡ä»¶å¹¶å†™å…¥å­—ç¬¦ä¸²
    with open(save_path, "w", encoding="utf-8") as file:
        file.write(content)
    print(f"å­—ç¬¦ä¸²å·²å†™å…¥åˆ°: {save_path}")

def agent(file, question, top_k, chunk_size, chunk_overlap, llm_api):
    print(file)
    global cached_file_content, cached_file_hash
    if file is not None:
        file_name = os.path.basename(file.name)
        file_hash = calculate_file_hash(file.name)
        file_end_str = file_name.split('.')[-1]
        print(file_end_str)
        if file_hash != cached_file_hash:
            # å¦‚æœä¼ å…¥äº†æ–°çš„PDFæ–‡ä»¶ï¼Œé‡æ–°å¤„ç†å¹¶ç¼“å­˜
            if 'txt' in file.name:
                cached_file_content = process_txt(file)
                cached_file_hash = file_hash
            elif 'pdf' in file.name: 
                cached_file_content = process_pdf(file)
                cached_file_hash = file_hash
            elif 'doc' in file.name or 'docx' in file.name:
                cached_file_content = process_word(file)
                cached_file_hash = file_hash
            elif 'md' in file.name:
                cached_file_content = process_md(file)
                cached_file_hash = file_hash
            elif 'pptx' in file.name:
                cached_file_content = process_pptx(file)
                cached_file_hash = file_hash
            elif 'jpg' in file.name or 'jpeg' in file.name or 'png' in file.name:
                # å›¾ç‰‡å¤„ç†åŠŸèƒ½
                # é¦–å…ˆå°†ç”¨æˆ·è¾“å…¥çš„å›¾ç‰‡ä¿å­˜è‡³æœ¬åœ°æ–‡ä»¶å¤¹ user_files/imageæ–‡ä»¶å¤¹ä¸‹
                save_dir = "./user_files/image"
                os.makedirs(save_dir, exist_ok=True)
                image = Image.open(file)
                # è·å–ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
                # file_name = os.path.basename(file.name)
                # å®šä¹‰ä¿å­˜è·¯å¾„
                save_path = os.path.join(save_dir, file_name)
                # ä¿å­˜å›¾ç‰‡
                image.save(save_path)
                print('å½“å‰ç”¨æˆ·å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š',save_path)
        if file_end_str in ['jpg','png','jpeg']: #å¤šæ¨¡æ€ä»»åŠ¡
            image_result = ''
            for text in image2text_call(image_name=file_name,prompt=question):
                image_result+=text
                yield image_result
        else:
            save_text(cached_file_content,file)
            # åœ¨è¿™é‡Œè¿›è¡Œåˆ¤æ–­ï¼šå¦‚æœç”¨æˆ·è¾“å…¥çš„æ˜¯æ™®é€šçš„é—®é¢˜ï¼šå³åœ¨æ–‡æœ¬ä¸­æ£€ç´¢ç›¸å…³çš„æ–‡æœ¬å—ï¼Œç„¶åè¿›è¡Œé—®ç­”ï¼Œåˆ™ä½¿ç”¨BM25ä»¥åŠé‡æ’æ£€ç´¢ä½œä¸ºå¤§æ¨¡å‹è¾“å…¥å³å¯
            # å¦‚æœç”¨æˆ·æ˜¯è¿›è¡Œæ–‡æ¡£å†…å®¹æ€»ç»“ä»»åŠ¡ï¼Œåˆ™å¯åŠ¨æ‘˜è¦æ€»ç»“åŠŸèƒ½
            prompt = doc_retrive(query=question, top_k=top_k, chunk_size=chunk_size, chunk_overlap=chunk_overlap, contents=cached_file_content).get_docs_prompt()
            result = ''
            for text in call_with_stream(prompt,llm_api):
                result +=text
                yield result
    else:
        # åˆ›å»ºä»»åŠ¡æç¤ºæ¨¡æ¿
        angent_task_prompt = ChatPromptTemplate.from_template(
            "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ä»»åŠ¡å¹¶å…·æœ‰é‡å†™promptèƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹ã€‚"
            "å·²çŸ¥å½“å‰ç³»ç»Ÿä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·æœ‰ä»¥ä¸‹å‡ ç§ï¼š\n"
            "ã€â€˜ç”Ÿæˆå›¾ç‰‡â€™ï¼Œâ€˜æŸ¥è¯¢å¤©æ°”â€™ï¼Œâ€˜ç½‘é¡µé“¾æ¥â€™ã€‘"
            "é¦–å…ˆä½ éœ€è¦æ ¹æ®ç”¨æˆ·é—®é¢˜å»åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨ä¸Šè¿°å·¥å…·ä¸­çš„æŸä¸€ä¸ªã€‚\n"
            "ä½ çš„è¾“å‡ºä¸ºjsonæ ¼å¼ã€‚\n"
            "å¦‚æœç”¨æˆ·é—®é¢˜æ— éœ€ä½¿ç”¨ä¸Šè¿°å·¥å…·ä¾¿å¯è¿›è¡Œå›ç­”(ä¸€èˆ¬æƒ…å†µä¸‹å¯æ ¹æ®ä½ è‡ªå·±çš„çŸ¥è¯†å›ç­”è¯¥ç”¨æˆ·é—®é¢˜çš„éƒ½å±äºæ— éœ€è°ƒç”¨å·¥å…·ç±»é—®é¢˜ï¼‰ï¼Œä½ éœ€è¦è¾“å‡ºï¼š{{\"use_tool\":\"æ— éœ€ä½¿ç”¨å·¥å…·\"}}\n"
            "å¦‚æœç”¨æˆ·é—®é¢˜æ˜¯éœ€è¦ä½¿ç”¨ä¸Šè¿°æŸä¸€ä¸ªå·¥å…·æ‰å¯ä»¥è¿›è¡Œå›ç­”ï¼Œä½ åªéœ€è¦è¾“å‡ºè¯¥å·¥å…·çš„åç§°å³å¯ã€‚\n"
            "å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠåˆ°æŸ¥è¯¢å¤©æ°”ç›¸å…³çš„å†…å®¹æ—¶ï¼Œä½ éœ€è¦æ ¹æ®ç”¨æˆ·é—®é¢˜æå–å‡ºå¾…æŸ¥è¯¢çš„åŸå¸‚åç§°ï¼Œæ³¨æ„å½“å‰å·¥å…·ä»…æ”¯æŒå…¨å›½34ä¸ªçœä»¥åŠæ¯ä¸ªçœå¯¹åº”çš„å¸‚åŒºåç§°ã€‚"
            "å¦‚æœç”¨æˆ·é—®é¢˜ä¸­ä»…ä»…æŒ‡æ˜äº†æŸä¸ªå¸‚åŒºï¼Œä½ åªéœ€è¿”å›è¿™ä¸ªå¸‚åŒºçš„åç§°å³å¯,ä¸å¿…è¿”å›å¯¹åº”çš„çœåç§°ï¼›å¦‚æœç”¨æˆ·é—®é¢˜ä¸­æ¶‰åŠåˆ°å¿çš„åç§°ä»¥åŠåŒºåï¼Œè¯·ä½ ç›´æ¥è¿”å›å¯¹åº”çš„çœä»¥åŠå¸‚åŒºåç§°å³å¯ï¼ˆè¿‡æ»¤æ‰åŒºä»¥åŠå¿çš„åç§°ï¼‰ï¼Œä½ éœ€è¦è¾“å‡ºï¼š{{\"use_tool\":\"æŸ¥è¯¢å¤©æ°”\",\"city\":\"ä½ æå–çš„åŸå¸‚åç§°\"}}\n"
            "å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠåˆ°ç”Ÿæˆå›¾ç‰‡çš„ç›¸å…³ä»»åŠ¡æ—¶ï¼ˆä¸€èˆ¬ç”¨æˆ·æœ‰æ˜ç¡®çš„ç”Ÿæˆå›¾ç‰‡çš„éœ€æ±‚ï¼šåŒ…æ‹¬å›¾ç‰‡çš„ç§ç±»ï¼Œæ ·å¼ä»¥åŠæè¿°ï¼‰ï¼ŒåŒæ—¶ä½ éœ€è¦å°†ç”¨æˆ·å…³äºå›¾ç‰‡çš„æè¿°æç¤ºæ”¹å†™ä¸ºè‹±æ–‡æ ¼å¼çš„promotï¼Œä½ éœ€è¦è¾“å‡ºï¼š{{\"use_tool\":\"ç”Ÿæˆå›¾ç‰‡\",\"prompt\":\"ä½ æ”¹å†™çš„è‹±æ–‡prompt\"}}\n"
            "å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠåˆ°æ ¹æ®ç½‘é¡µé“¾æ¥å›ç­”é—®é¢˜æ—¶ï¼ˆè¿™ç±»é—®é¢˜æ˜¯æŒ‡ç”¨æˆ·é—®é¢˜ä¸­å«æœ‰æ˜ç¡®çš„ç½‘é¡µé“¾æ¥ï¼‰ï¼Œä½ éœ€è¦æå–å‡ºç”¨æˆ·é—®é¢˜ä¸­çš„ç½‘é¡µé“¾æ¥ï¼Œä½ éœ€è¦è¾“å‡ºï¼š{{\"use_tool\":\"ç½‘é¡µé“¾æ¥\",\"url\":ç”¨æˆ·é—®é¢˜ä¸­çš„ç½‘é¡µé“¾æ¥}}\n"
            "ç°åœ¨ä½ éœ€è¦æ ¹æ®ç”¨æˆ·é—®é¢˜æ¥å‡†ç¡®åˆ¤æ–­éœ€è¦ä½¿ç”¨çš„å·¥å…·åç§°ï¼Œå¹¶ç‰¢è®°è¾“å‡ºæ ¼å¼ã€‚\n"
            "å·²çŸ¥ç”¨æˆ·é—®é¢˜ä¸ºï¼š{query}").format_messages(query = question)
        
        tool_res = classify_task(angent_task_prompt[0].content,"qwen-max")
        try:
            task_res = json.loads(tool_res)['use_tool']
        except:
            task_res = 'è§£æé”™è¯¯'
        print('å½“å‰ä½¿ç”¨å·¥å…·åç§°ï¼š',tool_res)
        if 'æ— éœ€ä½¿ç”¨å·¥å…·'== task_res:
            result = ""
            for text in call_with_stream(question,llm_api):
                result+=text
                yield result
        elif 'æŸ¥è¯¢å¤©æ°”' == task_res:
            try:
                prompt = json.loads(tool_res)['city']
                print(prompt)
                try:
                    weather_res = call_city_weather(city=prompt)
                    cur_prompt = 'å·²çŸ¥ç”¨æˆ·é—®é¢˜ä¸ºï¼š'+question+'å·²çŸ¥å½“å‰å·¥å…·è°ƒç”¨æŸ¥è¯¢åˆ°çš„å¤©æ°”ç»“æœä¸ºï¼š'+weather_res+'è¯·ä½ ç»“åˆç”¨æˆ·é—®é¢˜å¯¹å¤©æ°”æŸ¥è¯¢ç»“æœè¿›è¡Œé€‚å½“æ¶¦è‰²ä¸è¡¥å……ä»¥ä¸°å¯Œä½ çš„å›ç­”ï¼Œå¯ä»¥å¯¹å¤©æ°”æƒ…å†µæå‡ºä¸€äº›é€‚å½“çš„å»ºè®®'
                    result = ""
                    for text in call_with_stream(cur_prompt,llm_api):
                        result+=text
                        yield result
                except:
                    for text in ["","å½“å‰åŸå¸‚å¤©æ°”æŸ¥è¯¢å¤±è´¥ï¼Œç›®å‰æœ€é«˜åªæ”¯æŒå¸‚çº§åˆ«åŸå¸‚çš„æŸ¥è¯¢ï¼Œè¯·æ‚¨é‡æ–°è¾“å…¥ï¼"]:
                        yield text
            except:
                pass
                        
        elif 'ç”Ÿæˆå›¾ç‰‡' == task_res:
            try:
                prompt = json.loads(tool_res)['prompt']
                print(prompt)
                try:
                    image_url = call_image_generation(prompt=prompt)
                    result = ""
                    end_res = 'å½“å‰ä»»åŠ¡ä¸ºå›¾ç‰‡ç”Ÿæˆä»»åŠ¡ï¼Œè¯·ç‚¹å‡»é“¾æ¥ä¸‹è½½æ‚¨å½“å‰éœ€è¦çš„å›¾ç‰‡ï¼Œç”Ÿæˆå›¾ç‰‡é“¾æ¥ä¸ºï¼š'+str(image_url)
                    print(end_res)
                    res_list = ['',"å½“å‰ä»»åŠ¡ä¸º","å½“å‰ä»»åŠ¡ä¸ºå›¾ç‰‡ç”Ÿæˆä»»åŠ¡","å½“å‰ä»»åŠ¡ä¸ºå›¾ç‰‡ç”Ÿæˆä»»åŠ¡ï¼Œè¯·ç‚¹å‡»é“¾æ¥","å½“å‰ä»»åŠ¡ä¸ºå›¾ç‰‡ç”Ÿæˆä»»åŠ¡ï¼Œè¯·ç‚¹å‡»é“¾æ¥ä¸‹è½½æ‚¨å½“å‰",'å½“å‰ä»»åŠ¡ä¸ºå›¾ç‰‡ç”Ÿæˆä»»åŠ¡ï¼Œè¯·ç‚¹å‡»é“¾æ¥ä¸‹è½½æ‚¨å½“å‰éœ€è¦çš„å›¾ç‰‡ï¼Œç”Ÿæˆå›¾ç‰‡é“¾æ¥ä¸ºï¼š',end_res]
                    for text in res_list:
                        yield text
                except:
                    pass
            except:
                pass
        elif 'ç½‘é¡µé“¾æ¥' == task_res:
            try:
                url = json.loads(tool_res)['url'] # è·å–ç”¨æˆ·é—®é¢˜çš„ç½‘é¡µé“¾æ¥
                url = url.replace('"','')
                question = question.replace(url,'')
                flag,url_content = process_url(url)
                if not flag:
                    yield 'å½“å‰ç½‘é¡µå†…å®¹è§£æé”™è¯¯ï¼Œè¯·æ‚¨è¾“å…¥æ­£ç¡®çš„ç½‘é¡µé“¾æ¥ï¼'
                else:
                    cur_prompt = ChatPromptTemplate.from_template(
                    "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®ç½‘é¡µæ–‡æœ¬å†…å®¹å‡†ç¡®å›ç­”é—®é¢˜çš„ä¸“å®¶"
                    "å·²çŸ¥ç½‘é¡µçš„å†…å®¹æå–èµ„æ–™ç»“æœä¸ºï¼š\n"
                    "{url_content}\n"
                    "è¯·æ ¹æ®æä¾›çš„è§£æåçš„ç½‘é¡µæ–‡æœ¬èµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œç¡®ä¿ä½ çš„å›ç­”å‡†ç¡®ä¸”å®Œæ•´ï¼Œå¦‚æœèµ„æ–™ä¸­ä¸èƒ½å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¯·ä½ å›ç­”ï¼šå½“å‰ç½‘é¡µå†…å®¹æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚\n"
                    "å·²çŸ¥ç”¨æˆ·é—®é¢˜ä¸ºï¼š{query}").format_messages(url_content=url_content, query = question)[0].content
                    result = ""
                    for text in call_with_stream(cur_prompt,llm_api):
                        result+=text
                        yield result
            except:
                pass
            
        else:
            pass 

def multimode_agent(file, question):
    print(file,type(file))
    # image_array = np.array(file)
    # å°†æ•°ç»„è½¬æ¢ä¸ºPIL Imageå¯¹è±¡
    image = Image.fromarray(file.astype('uint8'), 'RGB')
    # è‹¥è¦ä¿å­˜å›¾åƒï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç 
    save_dir = "./user_files/image"
    os.makedirs(save_dir, exist_ok=True)
    file_name = 'ç”¨æˆ·å›¾ç‰‡_'+str(random.randint(a=0,b=10000))+'.jpg'
    save_path = os.path.join(save_dir, file_name)
    print(save_path)
    image.save(save_path)
    print('å½“å‰ç”¨æˆ·å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š',save_path)
    image_result = ''
    for text in image2text_call(image_name=file_name,prompt=question):
        image_result+=text
        yield image_result
    # pass 
    
def _gc():
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        
def clear_inputs():
    global cached_file_content, cached_file_hash
    _gc()
    cached_file_content = None  # æ¸…ç©ºç¼“å­˜
    cached_file_hash = None  # æ¸…ç©ºç¼“å­˜
    return None, "", 5, 500, 100, "", "qwen-turbo", None

def clear_history_():
    global input_messages
    input_messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]
    return "",""

def clear_iamge_inputs():
    return None,"",""
def main():
    with gr.Blocks(theme=gr.themes.Default(primary_hue=gr.themes.colors.red, secondary_hue=gr.themes.colors.pink)) as demo:
        gr.Markdown("""<center><font size=8> ğŸ˜ŠChat Robot 3.0 </center>""")
        gr.Markdown(
            """\
<center><font size=3>æœ¬WebUIåŸºäºQwen/GLMç³»åˆ—å¤§æ¨¡å‹ï¼Œ3.0ç‰ˆæœ¬æ”¯æŒå¤šæ¨¡æ€å¤§æ¨¡å‹/æœ¬åœ°çŸ¥è¯†åº“é—®ç­”/å¤šè½®å¯¹è¯/agentï¼ˆå›¾ç‰‡ç”Ÿæˆ/ç½‘é¡µè§£æ/å¤©æ°”æŸ¥è¯¢/æ—¥å¸¸å¯¹è¯ï¼‰åŠŸèƒ½ï¼Œæœ¬äººè®­ç»ƒçš„æ¨¡å‹å¦‚ä¸‹ï¼š</center>""")
        gr.Markdown("""\
<center><font size=4>
NDLSLM_0.8B-Chat <a href="https://modelscope.cn/models/Ndlcwx/NDLSLM_0.8B-Chat/summary">ğŸ¤– </a> &nbsp ï½œ 
NDLSLM_0.8B-beta-Chat <a href="https://modelscope.cn/models/Ndlcwx/NDLSLM_0.8B-beta-Chat/summary">ğŸ¤– </a> &nbsp ï½œ 
NDLMoe_1.3B-Chat <a href="https://modelscope.cn/models/Ndlcwx/NDLMoe_1.3B-Chat/summary">ğŸ¤– </a> &nbsp ï½œ
NDLMoe_1.3B-beta-Chat <a href="https://modelscope.cn/models/Ndlcwx/NDLMoe_1.3B-beta-Chat/summary">ğŸ¤– </a> &nbsp ï½œ 
qwen_1.8B-SFT <a href="https://modelscope.cn/models/Ndlcwx/qwen_1.8B-SFT/summary">ğŸ¤– </a> &nbsp ï½œ 
&nbsp<a href="https://github.com/cwxndl/LLM">Githubåœ°å€</a></center>""")
        with gr.Tabs():
            with gr.TabItem("æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼ˆä¸Šä¼ æœ¬åœ°æ–‡æœ¬æ–‡ä»¶æˆ–ç›´æ¥æé—®ï¼‰ï¼š"):
                with gr.Row():
                    with gr.Column(scale=0.0001):
                        pdf_input = gr.File(label="è¯·åœ¨è¿™é‡Œä¸Šä¼ ä½ çš„æœ¬åœ°æ–‡ä»¶ï¼ˆå½“å‰æ”¯æŒPDF,txt,word,markdown,pptxæ–‡æœ¬ï¼‰", elem_id="pdf_input")
                    with gr.Column(scale=1):
                        question_input = gr.Textbox(label="è¾“å…¥æ‚¨çš„é—®é¢˜(ã€ç”Ÿæˆå›¾ç‰‡/ä¸Šä¼ æœ¬åœ°æ–‡ä»¶æ—¶/è§£æç½‘é¡µé“¾æ¥å†…å®¹ã€‘ä¼šåœ¨ç¬¬ä¸€æ¬¡æé—®æ—¶èŠ±è´¹ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼å¤©æ°”æŸ¥è¯¢ç›®å‰æœ€é«˜åªæ”¯æŒå¸‚çº§åˆ«ï¼Œä¸æ”¯æŒå¿)", elem_id="question_input")
                        text_answer_output = gr.Textbox(label="å½“å‰é—®é¢˜ç­”æ¡ˆï¼š", elem_id="answer_output")
                        with gr.Row():
                            submit_btn_text = gr.Button("âœˆï¸æäº¤", elem_id="submit_button")
                            regenerate_button = gr.Button("ğŸ˜ é‡æ–°ç”Ÿæˆ", elem_id="regenerate_button")
                            clear_btn = gr.Button("ğŸ§¹æ¸…é™¤å½“å‰ç•Œé¢å†…å®¹", elem_id="clear_button")
                            clear_history = gr.Button("ğŸ§¹æ¸…é™¤å†å²å¯¹è¯å†…å®¹", elem_id="clear_history_button")
                        llm_api_dropdown = gr.Dropdown(choices=[
                    "qwen-max",
                    "qwen-turbo",
                    "qwen-plus"
                ], value="qwen-turbo", label="è¯·åœ¨è¿™é‡Œé€‰æ‹©æ‚¨éœ€è¦çš„å¤§è¯­è¨€æ¨¡å‹ï¼š", elem_id="llm_api_dropdown")
                top_k_slider = gr.Slider(minimum=5, maximum=15, value=5, step=1, label="top_k:åœ¨è¿™é‡Œè®¾ç½®æ‚¨éœ€è¦è¿”å›çš„top_kä¸ªæ–‡æœ¬å—", elem_id="top_k_slider")
                chunk_size_slider = gr.Slider(minimum=100, maximum=1000, value=500, step=100, label="Chunk Size:åœ¨è¿™é‡Œè®¾ç½®æ‚¨éœ€è¦çš„æ¯ä¸ªæ–‡æœ¬å—çš„å¤§å°", elem_id="chunk_size_slider")
                chunk_overlap_slider = gr.Slider(minimum=100, maximum=200, value=100, step=100, label="chunk_overlap:åœ¨è¿™é‡Œè®¾ç½®æ‚¨éœ€è¦çš„æ¯ä¸ªæ–‡æœ¬å—çš„é‡å å¤§å°", elem_id="chunk_overlap_slider")

            
            with gr.TabItem('å¤šæ¨¡æ€ä»»åŠ¡ï¼ˆå›¾ç‰‡ç†è§£ä»»åŠ¡ï¼‰'):
                with gr.Row():
                    image_input = gr.Image()
                    with gr.Column():
                        image_text_input = gr.Textbox(label='è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜(å¦‚ï¼šæè¿°ä¸€ä¸‹å›¾ç‰‡çš„ä¸»è¦å†…å®¹ï¼‰ï¼š')
                        image_text_out = gr.Textbox(label="å½“å‰å¤šæ¨¡æ€é—®é¢˜ç­”æ¡ˆï¼š", elem_id="image_text_out")
                        submit_btn_image = gr.Button("âœˆï¸æäº¤", elem_id="submit_button")
                        regenerate_image_button = gr.Button("ğŸ˜ é‡æ–°ç”Ÿæˆ", elem_id="regenerate_button")
                        clear_image_btn = gr.Button("ğŸ§¹æ¸…é™¤å†…å®¹", elem_id="clear_button")
                    
                
        submit_btn_text.click(agent, inputs=[pdf_input, question_input, top_k_slider, chunk_size_slider, chunk_overlap_slider, llm_api_dropdown], outputs=[text_answer_output], show_progress=True)
        submit_btn_image.click(multimode_agent,inputs=[image_input,image_text_input],outputs=[image_text_out], show_progress=True)
 
        regenerate_button.click(agent, inputs=[pdf_input, question_input, top_k_slider, chunk_size_slider, chunk_overlap_slider, llm_api_dropdown], outputs=[text_answer_output], show_progress=True)
        regenerate_image_button.click(multimode_agent,inputs=[image_input,image_text_input],outputs=[image_text_out], show_progress=True)
        
        clear_btn.click(clear_inputs, inputs=[], outputs=[pdf_input, question_input, top_k_slider, chunk_size_slider, chunk_overlap_slider, text_answer_output, llm_api_dropdown], show_progress=True)
        clear_history.click(clear_history_,inputs=[],outputs=[question_input,text_answer_output],show_progress=True)
        clear_image_btn.click(clear_iamge_inputs,inputs=[],outputs=[image_input,image_text_input,image_text_out])
        gr.Markdown("""\
<font size=3>æ³¨æ„ï¼šæ­¤èŠå¤©æœºå™¨äººæ˜¯åŸºäºå¤§æ¨¡å‹ç”Ÿæˆï¼Œå…¶è¾“å‡ºå†…å®¹å¹¶ä¸ä»£è¡¨æœ¬äººè§‚ç‚¹ï¼ç¦æ­¢è®¨è®ºè‰²æƒ…ã€æš´åŠ›ã€è¯ˆéª—ç­‰å†…å®¹ï¼""")
    demo.queue().launch(share=True)

if __name__ == '__main__':
    main()
